{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 1 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "\n",
    "def get_column(data, index): ## duyet qua tung cot \n",
    "    result  = [ row[index] for row in data]  # lay du lieu tung dong cua moi cot\n",
    "    \n",
    "    return result\n",
    "\n",
    "def prepare_data(file_name_dataset):\n",
    "    data = np.genfromtxt(file_name_dataset, delimiter=',', skip_header=1).tolist()\n",
    "    N = len(data)  \n",
    "\n",
    "    tv_data = get_column(data, 0) \n",
    "    \n",
    "    radio_data = get_column(data , 1)\n",
    "    \n",
    "    newspaper_data = get_column(data , 2)\n",
    "    \n",
    "    sales_data = get_column(data , 3) \n",
    "    \n",
    "    # X(input), y(output)\n",
    "    X = [tv_data, radio_data, newspaper_data]\n",
    "    y = sales_data\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = prepare_data(r\"E:\\advertising (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[624.1, 175.10000000000002, 300.5, 78.9]\n"
     ]
    }
   ],
   "source": [
    "list = [sum(X[0][:5]), sum(X[1][:5]), sum(X[2][:5]), sum(y[:5]) ]\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 2: One sample - linear regression ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1: initialize_params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params():\n",
    "    w1 , w2 , w3 , b = (0.016992259082509283 , 0.0070783670518262355 , -0.002307860847821344 , 0)\n",
    "    return w1 , w2 , w3 , b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x1, x2, x3, w1, w2, w3, b):\n",
    "    y_hat = [w1 * x1 + w2 * x2 + w3 * x3 + b ]\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, y_hat):\n",
    "    loss = sum( (y_hat[i] - y[i]) ** 2 for i in range(len(y)) ) \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_wi(xi, y, y_hat):\n",
    "    dl_dwi = 2 * xi * (y_hat - y)\n",
    "    \n",
    "    return dl_dwi\n",
    "\n",
    "def compute_gradient_b(y, y_hat):\n",
    "    dl_dwb = 2 * (y_hat - y)\n",
    "    \n",
    "    return dl_dwb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weight_wi(wi, dl_dwi, lr):\n",
    "    wi = wi -  lr * dl_dwi\n",
    "    \n",
    "    return wi\n",
    "\n",
    "def update_weight_b(dl_dwb, lr):\n",
    "    b = b - lr * dl_dwb\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_linear_regression(X_data, y_data , max_epochs = 50, lr = 1e-5):\n",
    "    losses = []\n",
    "    N = len(y_data)\n",
    "    w1, w2, w3, b = initialize_params()\n",
    "    for epoch in range(max_epochs):\n",
    "        for i in range(N):\n",
    "            ## sample \n",
    "            x1 = X_data[0][i]\n",
    "            x2 = X_data[1][i]\n",
    "            x3 = X_data[2][i]\n",
    "            y = y_data[i]\n",
    "            \n",
    "            ## compute ouput \n",
    "            y_hat  = predict(x1,x2,x3,w1,w2,w3,b)\n",
    "            \n",
    "            ## loss\n",
    "            loss = compute_loss(y_hat, y)\n",
    "        \n",
    "            \n",
    "            ## gradient \n",
    "            dl_dw1 = compute_gradient_wi(x1, y, y_hat)\n",
    "            dl_dw2 = compute_gradient_wi(x2, y, y_hat)\n",
    "            dl_dw3 = compute_gradient_wi(x3, y, y_hat )\n",
    "            dl_db = compute_gradient_b(y, y_hat)\n",
    "            \n",
    "            ##  update gradient \n",
    "            w1 = update_weight_wi(w1, dl_dw1, lr)\n",
    "            w2 = update_weight_wi(w2, dl_dw2, lr)\n",
    "            w3 = update_weight_wi(w3, dl_dw3, lr)\n",
    "            b = update_weight_b(dl_db, lr)\n",
    "            \n",
    "        losses.append(loss)\n",
    "\n",
    "    return w1, w2, w3, b , losses     \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m (w1, w2, w3, b , losses) \u001b[38;5;241m=\u001b[39m implement_linear_regression(X, y)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(losses[:\u001b[38;5;241m100\u001b[39m])\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m, in \u001b[0;36mimplement_linear_regression\u001b[1;34m(X_data, y_data, max_epochs, lr)\u001b[0m\n\u001b[0;32m     14\u001b[0m y_hat  \u001b[38;5;241m=\u001b[39m predict(x1,x2,x3,w1,w2,w3,b)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m## loss\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m loss \u001b[38;5;241m=\u001b[39m compute_loss(y_hat, y)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m## gradient \u001b[39;00m\n\u001b[0;32m     21\u001b[0m dl_dw1 \u001b[38;5;241m=\u001b[39m compute_gradient_wi(x1, y, y_hat)\n",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m, in \u001b[0;36mcompute_loss\u001b[1;34m(y, y_hat)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(y, y_hat):\n\u001b[1;32m----> 2\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m( (y_hat[i] \u001b[38;5;241m-\u001b[39m y[i]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y)) ) \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(y, y_hat):\n\u001b[1;32m----> 2\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m( (y_hat[i] \u001b[38;5;241m-\u001b[39m y[i]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y)) ) \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "(w1, w2, w3, b , losses) = implement_linear_regression(X, y)\n",
    "plt.plot(losses[:100])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.title('Loss over Iterations')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bài tập 3 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Hàm khởi tạo tham số ban đầu\n",
    "def initialize_params():\n",
    "    w1, w2, w3, b = 0.0, 0.0, 0.0, 0.0\n",
    "    return w1, w2, w3, b\n",
    "\n",
    "# Hàm dự đoán kết quả\n",
    "def predict(x1, x2, x3, w1, w2, w3, b):\n",
    "    return w1 * x1 + w2 * x2 + w3 * x3 + b\n",
    "\n",
    "# Hàm tính toán Mean Squared Error (MSE)\n",
    "def compute_loss_mse(y, y_hat):\n",
    "    return np.mean((y_hat - y) ** 2)\n",
    "\n",
    "# Hàm tính gradient đối với w\n",
    "def compute_gradient_wi(xi, y, y_hat):\n",
    "    return 2 * xi * (y_hat - y)\n",
    "\n",
    "# Hàm tính gradient đối với b\n",
    "def compute_gradient_b(y, y_hat):\n",
    "    return 2 * (y_hat - y)\n",
    "\n",
    "# Hàm cập nhật trọng số w\n",
    "def update_weight_wi(wi, dl_dwi, lr):\n",
    "    wi -= lr * dl_dwi\n",
    "    return wi\n",
    "\n",
    "# Hàm cập nhật bias b\n",
    "def update_weight_b(b, dl_db, lr):\n",
    "    b -= lr * dl_db\n",
    "    return b\n",
    "\n",
    "# Hàm chính triển khai Linear Regression với N samples\n",
    "def implement_linear_regression_nsamples(X_data, y_data, epoch_max=50, lr=1e-5):\n",
    "    losses = []\n",
    "\n",
    "    # Khởi tạo các trọng số\n",
    "    w1, w2, w3, b = initialize_params()\n",
    "    N = len(y_data)\n",
    "\n",
    "    for epoch in range(epoch_max):\n",
    "        loss_total = 0.0\n",
    "        dw1_total, dw2_total, dw3_total, db_total = 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "        for i in range(N):\n",
    "            # Lấy mẫu\n",
    "            x1 = X_data[0][i]\n",
    "            x2 = X_data[1][i]\n",
    "            x3 = X_data[2][i]\n",
    "            y = y_data[i]\n",
    "\n",
    "            # Tính toán đầu ra dự đoán\n",
    "            y_hat = predict(x1, x2, x3, w1, w2, w3, b)\n",
    "\n",
    "            # Tính loss\n",
    "            loss = compute_loss_mse(y, y_hat)\n",
    "            loss_total += loss\n",
    "\n",
    "            # Tính toán gradient\n",
    "            dl_dw1 = compute_gradient_wi(x1, y, y_hat)\n",
    "            dl_dw2 = compute_gradient_wi(x2, y, y_hat)\n",
    "            dl_dw3 = compute_gradient_wi(x3, y, y_hat)\n",
    "            dl_db = compute_gradient_b(y, y_hat)\n",
    "\n",
    "            # Cộng dồn gradient\n",
    "            dw1_total += dl_dw1\n",
    "            dw2_total += dl_dw2\n",
    "            dw3_total += dl_dw3\n",
    "            db_total += dl_db\n",
    "\n",
    "        # Cập nhật trọng số sau khi xử lý N samples\n",
    "        w1 = update_weight_wi(w1, dw1_total/N, lr)\n",
    "        w2 = update_weight_wi(w2, dw2_total/N, lr)\n",
    "        w3 = update_weight_wi(w3, dw3_total/N, lr)\n",
    "        b = update_weight_b(b, db_total/N, lr)\n",
    "\n",
    "        # Ghi lại loss sau mỗi epoch\n",
    "        losses.append(loss_total/N)\n",
    "\n",
    "    return w1, w2, w3, b, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256.71195, 52.65010290927025, 20.283298098283485, 15.011588576967062, 14.01972270036175, 13.707744424210272, 13.507507673524126, 13.32923233051219, 13.158619567543015, 12.99328423254281, 12.832724966347413, 12.67674155221604, 12.525185080692303, 12.377918411064986, 12.234809817361162, 12.09573187386356, 11.960561170850848, 11.82917816474629, 11.70146705278111, 11.577315654729139, 11.456615298859603, 11.339260711560138, 11.22514991044883, 11.114184100855192, 11.006267575561935, 10.901307617705047, 10.799214406732014, 10.699900927322501, 10.603282881177375, 10.509278601586438, 10.417808970686778, 10.328797339327222, 10.24216944945669, 10.157853358956947, 10.075779368842706, 9.995879952754546, 9.918089688672344, 9.84234519277925, 9.768585055408549, 9.696749779007611, 9.626781718055517, 9.55862502087277, 9.492225573263452, 9.427530943932078, 9.364490331619216, 9.303054513901877, 9.243175797605971, 9.184807970780247, 9.127906256182397, 9.072427266229742, 9.018328959368338, 8.965570597815763, 8.914112706634443, 8.863917034093408, 8.814946513278048, 8.767165224908466, 8.720538361328355, 8.675032191627531, 8.630614027862443, 8.58725219233999, 8.544915985931224, 8.503575657382434, 8.463202373592228, 8.42376819082414, 8.38524602682536, 8.34760963382292, 8.310833572369864, 8.274893186014426, 8.23976457676647, 8.205424581335933, 8.17185074811909, 8.139021314908883, 8.10691518730678, 8.075511917813794, 8.044791685579446, 8.014735276787821, 7.98532406566083, 7.956539996058965, 7.928365563661001, 7.900783798704242, 7.873778249267656, 7.847332965080918, 7.821432481842654, 7.796061806031947, 7.771206400197478, 7.746852168709381, 7.722985443959123, 7.699592972993338, 7.676661904567958, 7.654179776609407, 7.632134504070001, 7.610514367165178, 7.58930799998049, 7.56850437943681, 7.548092814602272, 7.528062936340275, 7.508404687282784, 7.48910831211874, 7.470164348187691, 7.451563616368934, 7.4332972122570276, 7.4153564976144715, 7.397733092092921, 7.380418865214512, 7.363405928605024, 7.346686628471008, 7.33025353831318, 7.3140994518686195, 7.298217376274598, 7.282600525447093, 7.267242313667095, 7.252136349368361, 7.2372764291200795, 7.222656531798436, 7.208270812941107, 7.194113599278896, 7.180179383438906, 7.166462818813979, 7.152958714593013, 7.139662030947178, 7.126567874367125, 7.113671493146366, 7.100968273006356, 7.088453732858642, 7.076123520699947, 7.063973409635832, 7.051999294029028, 7.040197185768466, 7.028563210655139, 7.0170936049012855, 7.005784711739079, 6.994632978135675, 6.983634951611004, 6.972787277155256, 6.962086694242819, 6.951530033939683, 6.941114216101355, 6.930836246658447, 6.9206932149871605, 6.910682291362056, 6.900800724488356, 6.891045839111544, 6.881415033701574, 6.871905778209474, 6.862515611894098, 6.853242141216645, 6.84408303780111, 6.835036036458215, 6.8260989332711945, 6.81726958374123, 6.8085459009907785, 6.79992585402296, 6.791407466035219, 6.782988812785524, 6.774668021009586, 6.766443266887311, 6.758312774557073, 6.750274814676255, 6.742327703026588, 6.734469799162938, 6.726699505104134, 6.719015264064449, 6.71141555922465, 6.703898912541183, 6.696463883592328, 6.689109068460311, 6.681833098648033, 6.67463464002946, 6.667512391832628, 6.660465085654137, 6.653491484504224, 6.646590381881477, 6.639760600876165, 6.633000993301357, 6.62631043885097, 6.619687844283816, 6.613132142632985, 6.606642292439529, 6.600217277009972, 6.593856103696672, 6.587557803200417, 6.581321428894577, 6.575146056170038, 6.5690307818004, 6.562974723326662, 6.556977018460942, 6.551036824508462, 6.545153317807355, 6.539325693185718, 6.533553163435285, 6.527834958801301, 6.522170326488061, 6.516558530179555, 6.510998849574874, 6.505490579937794, 6.50003303166015, 6.494625529838587, 6.489267413864229, 6.4839580370248635, 6.478696766119298, 6.473482981083455, 6.468316074627837, 6.463195451886091, 6.458120530074186, 6.453090738159991, 6.448105516542895, 6.443164316743114, 6.438266601100443, 6.433411842482072, 6.42859952399937, 6.423829138733048, 6.419100189466804, 6.414412188428839, 6.4097646570412765, 6.405157125677091, 6.400589133424265, 6.396060227857215, 6.391569964814846, 6.387117908185434, 6.382703629697858, 6.378326708719073, 6.373986732057697, 6.369683293773371, 6.365415994991814, 6.361184443725434, 6.356988254699193, 6.352827049181681, 6.348700454821174, 6.344608105486527, 6.340549641112807, 6.336524707551424, 6.3325329564247115, 6.3285740449847605, 6.324647635976399, 6.320753397504195, 6.316891002903317, 6.313060130614193, 6.309260464060836, 6.305491691532674, 6.301753506069784, 6.298045605351544, 6.294367691588402, 6.290719471416875, 6.2871006557974205, 6.283510959915454, 6.279950103084982, 6.27641780865514, 6.272913803919391, 6.269437820027212, 6.265989591898399, 6.262568858139758, 6.259175360964162, 6.25580884611184, 6.252469062773992, 6.249155763518441, 6.245868704217441, 6.242607643977452, 6.239372345070894, 6.236162572869817, 6.232978095781363, 6.229818685185067, 6.226684115371822, 6.223574163484568, 6.220488609460602, 6.217427235975423, 6.214389828388175, 6.211376174688495, 6.208386065444847, 6.205419293754232, 6.2024756551932505, 6.1995549477704746, 6.196656971880104, 6.193781530256817, 6.190928427931872, 6.188097472190302, 6.185288472529283, 6.18250124061763, 6.179735590256185, 6.176991337339466, 6.174268299818111, 6.171566297662407, 6.168885152826706, 6.166224689214748, 6.163584732645899, 6.160965110822225, 6.158365653296372, 6.1557861914402965, 6.153226558414765, 6.150686589139577, 6.1481661202645626, 6.145664990141312, 6.1431830387955255, 6.140720107900121, 6.138276040748913, 6.135850682231037, 6.133443878805856, 6.131055478478575, 6.128685330776343, 6.1263332867250515, 6.123999198826521, 6.121682921036304, 6.119384308742053, 6.117103218742269, 6.114839509225631, 6.112593039750768, 6.110363671226475, 6.108151265892409, 6.105955687300182, 6.103776800294913, 6.101614470997149, 6.0994685667852195, 6.097338956277962, 6.095225509317803, 6.093128096954237, 6.091046591427671, 6.088980866153549, 6.086930795706868, 6.084896255807031, 6.082877123302933, 6.08087327615848, 6.078884593438271, 6.076910955293702, 6.074952242949257, 6.073008338689107, 6.071079125844006, 6.0691644887783855, 6.06726431287776, 6.065378484536366, 6.0635068911450025, 6.061649421079164, 6.05980596368736, 6.057976409279656, 6.056160649116485, 6.0543585753975595, 6.052570081251134, 6.050795060723316, 6.049033408767675, 6.0472850212350195, 6.045549794863325, 6.043827627267865, 6.04211841693151, 6.040422063195224, 6.038738466248675, 6.03706752712104, 6.035409147671977, 6.033763230582715, 6.032129679347342, 6.030508398264174, 6.028899292427334, 6.027302267718431, 6.025717230798377, 6.024144089099346, 6.022582750816854, 6.021033124901964, 6.019495121053648, 6.017968649711183, 6.016453622046779, 6.014949949958223, 6.013457546061685, 6.011976323684612, 6.010506196858765, 6.009047080313283, 6.007598889467958, 6.006161540426499, 6.0047349499699685, 6.0033190355502635, 6.001913715283756, 6.000518907944931, 5.999134532960199, 5.997760510401742, 5.996396760981468, 5.995043206045035, 5.9936997675659685, 5.992366368139846, 5.991042930978581, 5.9897293799047375, 5.988425639345976, 5.987131634329526, 5.985847290476768, 5.984572533997859, 5.98330729168638, 5.98205149091422, 5.9808050596262845, 5.97956792633548, 5.978340020117617, 5.977121270606466, 5.97591160798884, 5.974710962999707, 5.9735192669174095, 5.97233645155894, 5.971162449275214, 5.969997192946449, 5.968840615977634, 5.967692652293909, 5.9665532363361935, 5.965422303056695, 5.964299787914552, 5.963185626871547, 5.962079756387759, 5.960982113417419, 5.959892635404648, 5.958811260279391, 5.9577379264532855, 5.956672572815624, 5.955615138729353, 5.954565564027117, 5.953523789007347, 5.952489754430335, 5.9514634015144825, 5.950444671932422, 5.949433507807314, 5.948429851709097, 5.9474336466508255, 5.946444836085025, 5.945463363900071, 5.94448917441665, 5.94352221238418, 5.9425624229773515, 5.941609751792647, 5.940664144844919, 5.939725548563974, 5.9387939097912295, 5.937869175776384, 5.936951294174096, 5.936040213040745, 5.9351358808311785, 5.934238246395498, 5.933347258975922, 5.932462868203602, 5.931585024095524, 5.930713677051426, 5.9298487778507365, 5.928990277649536, 5.92813812797758, 5.927292280735302, 5.926452688190881, 5.925619302977326, 5.924792078089557, 5.92397096688157, 5.923155923063579, 5.922346900699224, 5.921543854202732, 5.920746738336207, 5.919955508206853, 5.919170119264273, 5.91839052729778, 5.9176166884337205, 5.916848559132827, 5.916086096187593, 5.915329256719712, 5.914577998177438, 5.9138322783330715, 5.9130920552804405, 5.912357287432332, 5.91162793351808, 5.910903952581038, 5.9101853039761405, 5.909471947367522, 5.908763842726051, 5.908060950326995, 5.907363230747617, 5.9066706448648665, 5.905983153853036, 5.9053007191814375, 5.904623302612165, 5.903950866197774, 5.903283372279073, 5.902620783482884, 5.901963062719802, 5.901310173182063, 5.9006620783412975, 5.900018741946443, 5.899380128021553, 5.898746200863702, 5.898116925040884, 5.8974922653899045, 5.896872187014314, 5.896256655282397, 5.895645635825083, 5.895039094533948, 5.894436997559228, 5.893839311307783, 5.893246002441199, 5.8926570378737635, 5.8920723847705725, 5.891492010545579, 5.89091588285971, 5.890343969618955, 5.889776238972486, 5.889212659310804, 5.8886531992639, 5.888097827699417, 5.8875465137208085, 5.886999226665565, 5.8864559361034035, 5.885916611834522, 5.885381223887784, 5.88484974251905, 5.884322138209358, 5.883798381663266, 5.8832784438071135, 5.882762295787359, 5.882249908968862, 5.881741254933243, 5.881236305477239, 5.880735032611028, 5.88023740855663, 5.879743405746293, 5.879252996820868, 5.878766154628255, 5.8782828522217985, 5.877803062858721, 5.8773267599985966, 5.876853917301795, 5.876384508627947, 5.875918508034434, 5.875455889774895, 5.874996628297717, 5.874540698244558, 5.874088074448894, 5.873638731934531, 5.873192645914191, 5.872749791788051, 5.872310145142324, 5.871873681747859, 5.871440377558718, 5.871010208710815, 5.870583151520497, 5.870159182483191, 5.86973827827207, 5.869320415736637, 5.86890557190147, 5.868493723964839, 5.8680848492974, 5.867678925440877, 5.867275930106793, 5.866875841175155, 5.866478636693193, 5.8660842948740735, 5.865692794095658, 5.865304112899256, 5.864918229988369, 5.864535124227473, 5.864154774640785, 5.86377716041108, 5.863402260878453, 5.863030055539158, 5.8626605240444185, 5.862293646199231, 5.861929401961212, 5.861567771439477, 5.86120873489342, 5.860852272731653, 5.860498365510802, 5.860146993934471, 5.8597981388520335, 5.859451781257617, 5.859107902288927, 5.858766483226231, 5.858427505491236, 5.858090950646024, 5.857756800392004, 5.8574250365688405, 5.85709564115342, 5.856768596258796, 5.856443884133183, 5.856121487158919, 5.855801387851428, 5.8554835688582685, 5.855168012958085, 5.854854703059632, 5.854543622200789, 5.854234753547583, 5.853928080393233, 5.853623586157167, 5.8533212543840705, 5.8530210687429465, 5.852723013026179, 5.852427071148593, 5.8521332271465205, 5.851841465176892, 5.851551769516329, 5.851264124560223, 5.850978514821852, 5.850694924931491, 5.850413339635498, 5.850133743795477, 5.849856122387383, 5.849580460500652, 5.8493067433373644, 5.849034956211385, 5.8487650845474874, 5.848497113880584, 5.848231029854819, 5.847966818222792, 5.847704464844702, 5.847443955687587, 5.847185276824449, 5.846928414433506, 5.846673354797373, 5.8464200843022835, 5.846168589437291, 5.845918856793496, 5.845670873063296, 5.845424625039596, 5.845180099615057, 5.844937283781341, 5.8446961646283615, 5.844456729343541, 5.844218965211093, 5.843982859611248, 5.843748400019564, 5.843515574006207, 5.843284369235209, 5.843054773463786, 5.842826774541603, 5.8426003604101195, 5.842375519101855, 5.842152238739718, 5.841930507536323, 5.841710313793317, 5.841491645900691, 5.841274492336133, 5.841058841664347, 5.840844682536406, 5.840632003689101, 5.840420793944286, 5.840211042208234, 5.840002737471013, 5.839795868805842, 5.839590425368451, 5.839386396396492, 5.839183771208889, 5.8389825392052295, 5.838782689865169, 5.838584212747815, 5.838387097491123, 5.838191333811311, 5.83799691150226, 5.837803820434937, 5.837612050556803, 5.837421591891246, 5.837232434536989, 5.837044568667542, 5.836857984530611, 5.836672672447582, 5.836488622812909, 5.8363058260936045, 5.836124272828671, 5.8359439536285675, 5.835764859174657, 5.835586980218681, 5.835410307582225, 5.835234832156202, 5.835060544900297, 5.83488743684249, 5.834715499078507, 5.834544722771319, 5.834375099150649, 5.834206619512438, 5.834039275218364, 5.83387305769535, 5.8337079584350535, 5.833543968993393, 5.833381080990064, 5.83321928610804, 5.833058576093097, 5.832898942753378, 5.832740377958853, 5.832582873640916, 5.832426421791898, 5.832271014464576, 5.83211664377177, 5.8319633018858585, 5.831810981038322, 5.831659673519323, 5.8315093716772415, 5.831360067918252, 5.8312117547058575, 5.831064424560496, 5.83091807005908, 5.830772683834582, 5.830628258575608, 5.830484787025987, 5.830342261984339, 5.830200676303673, 5.830060022890959, 5.829920294706756, 5.82978148476476, 5.829643586131441, 5.829506591925632, 5.82937049531812, 5.829235289531267, 5.829100967838633, 5.82896752356456, 5.828834950083819, 5.82870324082119, 5.82857238925113, 5.828442388897371, 5.828313233332548, 5.828184916177835, 5.828057431102577, 5.827930771823926, 5.827804932106504, 5.82767990576199, 5.827555686648804, 5.827432268671756, 5.82730964578168, 5.827187811975092, 5.827066761293846, 5.826946487824792, 5.826826985699422, 5.826708249093579, 5.826590272227048, 5.826473049363297, 5.826356574809093, 5.826240842914221, 5.826125848071108, 5.826011584714539, 5.825898047321341, 5.825785230410029, 5.82567312854053, 5.8255617363138406, 5.825451048371731, 5.825341059396447, 5.825231764110385, 5.82512315727579, 5.825015233694478, 5.824907988207502, 5.8248014156948855, 5.824695511075313, 5.824590269305852, 5.824485685381627, 5.824381754335599, 5.8242784712381885, 5.824175831197093, 5.824073829356923, 5.823972460898971, 5.823871721040903, 5.823771605036521, 5.823672108175445, 5.82357322578289, 5.823474953219367, 5.823377285880416, 5.823280219196352, 5.8231837486319975, 5.823087869686434, 5.822992577892719, 5.822897868817652, 5.822803738061508, 5.822710181257788, 5.8226171940729685, 5.822524772206242, 5.82243291138929, 5.8223416073860434, 5.822250855992389, 5.822160653035978, 5.822070994375971, 5.821981875902796, 5.821893293537923, 5.821805243233618, 5.821717720972703, 5.821630722768358, 5.821544244663849, 5.821458282732339, 5.821372833076626, 5.821287891828964, 5.821203455150807, 5.821119519232571, 5.821036080293487, 5.820953134581292, 5.820870678372092, 5.820788707970085, 5.820707219707416, 5.820626209943901, 5.820545675066852, 5.820465611490864, 5.820386015657605, 5.820306884035622, 5.820228213120129, 5.820149999432793, 5.820072239521571, 5.819994929960477, 5.819918067349387, 5.819841648313878, 5.819765669504986, 5.819690127599056, 5.819615019297516, 5.819540341326724, 5.819466090437726, 5.819392263406143, 5.819318857031916, 5.81924586813918, 5.819173293576025, 5.8191011302143485, 5.819029374949686, 5.818958024701009, 5.81888707641054, 5.818816527043627, 5.818746373588507, 5.818676613056174, 5.818607242480181, 5.818538258916493, 5.81846965944331, 5.818401441160892, 5.818333601191405, 5.818266136678727, 5.81819904478833, 5.818132322707064, 5.818065967643047, 5.817999976825481, 5.817934347504467, 5.8178690769508945, 5.817804162456274, 5.817739601332518, 5.817675390911898, 5.817611528546799, 5.817548011609611, 5.817484837492551, 5.817422003607558, 5.817359507386093, 5.817297346279017, 5.817235517756448, 5.817174019307601, 5.817112848440653, 5.817052002682609, 5.8169914795791335, 5.816931276694447, 5.816871391611138, 5.816811821930065, 5.816752565270211, 5.816693619268517, 5.816634981579797, 5.816576649876551, 5.816518621848868, 5.816460895204293, 5.816403467667646, 5.816346336980976, 5.816289500903335, 5.816232957210734, 5.816176703695962, 5.816120738168492, 5.816065058454311, 5.816009662395853, 5.815954547851832, 5.815899712697127, 5.815845154822677, 5.815790872135336, 5.815736862557774, 5.8156831240283475, 5.815629654500988, 5.815576451945057, 5.815523514345268, 5.81547083970155, 5.815418426028938, 5.815366271357453, 5.815314373731996, 5.81526273121222, 5.815211341872461, 5.815160203801555, 5.815109315102806, 5.8150586738938275, 5.815008278306448, 5.814958126486602, 5.814908216594232, 5.814858546803168, 5.814809115301038, 5.814759920289157, 5.814710959982407, 5.814662232609176, 5.814613736411217, 5.814565469643551, 5.814517430574399, 5.814469617485035, 5.814422028669736, 5.814374662435651, 5.814327517102709, 5.814280591003518, 5.814233882483308, 5.814187389899777, 5.814141111623022, 5.814095046035477, 5.814049191531764, 5.814003546518644, 5.813958109414913, 5.8139128786512835, 5.8138678526703504, 5.813823029926442, 5.813778408885578, 5.813733988025352, 5.813689765834862, 5.813645740814605, 5.813601911476419, 5.813558276343359, 5.813514833949655, 5.813471582840581, 5.813428521572423, 5.813385648712349, 5.813342962838366, 5.813300462539202, 5.813258146414251, 5.8132160130734825, 5.813174061137361, 5.8131322892367745, 5.813090696012942, 5.813049280117359, 5.8130080402116855, 5.812966974967693, 5.812926083067193, 5.8128853632019455, 5.812844814073585, 5.812804434393566, 5.81276422288305, 5.812724178272884, 5.812684299303466, 5.812644584724748, 5.812605033296075, 5.812565643786208, 5.812526414973162, 5.812487345644213, 5.812448434595776, 5.812409680633371, 5.812371082571523, 5.812332639233714, 5.812294349452321, 5.812256212068523, 5.812218225932262, 5.812180389902156, 5.812142702845445, 5.81210516363793, 5.812067771163891, 5.812030524316038, 5.8119934219954565, 5.811956463111497, 5.81191964658179, 5.811882971332097, 5.811846436296324, 5.811810040416411, 5.811773782642292, 5.811737661931841, 5.811701677250776, 5.811665827572656, 5.811630111878768, 5.811594529158108, 5.811559078407292, 5.81152375863054, 5.811488568839543, 5.811453508053507, 5.811418575299024, 5.811383769610023, 5.811349090027758, 5.8113145356006966, 5.8112801053845, 5.8112457984419725, 5.811211613842974, 5.81117755066441, 5.811143607990147, 5.811109784910968, 5.811076080524523, 5.811042493935284, 5.811009024254482, 5.810975670600041, 5.810942432096583, 5.810909307875306, 5.810876297073994, 5.810843398836924, 5.8108106123148495, 5.810777936664922, 5.810745371050668, 5.810712914641938, 5.810680566614831, 5.810648326151688, 5.810616192441002, 5.810584164677424, 5.810552242061668, 5.810520423800486, 5.810488709106618, 5.81045709719876, 5.810425587301495, 5.810394178645265, 5.810362870466334, 5.810331662006725, 5.810300552514175, 5.810269541242126, 5.8102386274496345, 5.810207810401365, 5.810177089367537, 5.81014646362386, 5.810115932451554, 5.810085495137225, 5.810055150972889, 5.810024899255906, 5.809994739288928, 5.809964670379896, 5.809934691841955, 5.809904802993461, 5.8098750031579, 5.8098452916638665, 5.809815667845028, 5.8097861310400924]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(w1 , w2 , w3 ,b , losses ) = implement_linear_regression_nsamples (X , y , epoch_max =1000 , lr =1e-5)\n",
    "print ( losses )\n",
    "plt.plot ( losses )\n",
    "plt.xlabel (\"# epoch \")\n",
    "plt.ylabel (\"MSE Loss \")\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dự đoán: -0.9290585093208648, Loss: 530.3375358257238\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Hàm chuẩn bị dữ liệu\n",
    "def prepare_data(file_name_dataset):\n",
    "    data = np.genfromtxt(file_name_dataset, delimiter=',', skip_header=1).tolist()\n",
    "    \n",
    "    # Lấy dữ liệu từ các cột TV (x0), Radio (x1), Newspaper (x2)\n",
    "    tv_data = get_column(data, 0)\n",
    "    radio_data = get_column(data, 1)\n",
    "    newspaper_data = get_column(data, 2)\n",
    "    \n",
    "    # Lấy dữ liệu Sales (y)\n",
    "    sales_data = get_column(data, 3)\n",
    "    \n",
    "    # Tạo danh sách input X (các feature) và output Y (label)\n",
    "    X = [[1, x1, x2, x3] for x1, x2, x3 in zip(tv_data, radio_data, newspaper_data)]\n",
    "    y = sales_data\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Hàm lấy dữ liệu từ cột\n",
    "def get_column(data, index):\n",
    "    return [row[index] for row in data]\n",
    "\n",
    "# Hàm khởi tạo trọng số ban đầu\n",
    "def initialize_params():\n",
    "    bias = 0\n",
    "    w1 = random.gauss(mu=0.0, sigma=0.01)\n",
    "    w2 = random.gauss(mu=0.0, sigma=0.01)\n",
    "    w3 = random.gauss(mu=0.0, sigma=0.01)\n",
    "    \n",
    "    return [bias, w1, w2, w3]\n",
    "\n",
    "# Hàm dự đoán kết quả\n",
    "def predict(X_features, weights):\n",
    "    bias, w1, w2, w3 = weights\n",
    "    \n",
    "    # X_features chứa [x0, x1, x2, x3] trong đó x0 = 1\n",
    "    result = X_features[0] * bias + X_features[1] * w1 + X_features[2] * w2 + X_features[3] * w3\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Hàm tính toán loss (Mean Squared Error)\n",
    "def compute_loss(y_hat, y):\n",
    "    return (y_hat - y) ** 2\n",
    "\n",
    "# Hàm tính gradient\n",
    "def compute_gradient_w(X_features, y_hat, y):\n",
    "    return 2 * (y_hat - y) * X_features\n",
    "\n",
    "# Ví dụ sử dụng hàm\n",
    "file_name_dataset = r'E:\\advertising (1).csv'  \n",
    "X_data, y_data = prepare_data(file_name_dataset)\n",
    "\n",
    "# Khởi tạo các tham số ban đầu\n",
    "weights = initialize_params()\n",
    "\n",
    "# Ví dụ tính dự đoán và loss cho một mẫu dữ liệu\n",
    "y_hat = predict(X_data[0], weights)\n",
    "loss = compute_loss(y_hat, y_data[0])\n",
    "\n",
    "print(f'Dự đoán: {y_hat}, Loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
