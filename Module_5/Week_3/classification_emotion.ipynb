{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.io import read_image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility and define device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "random_state = 59\n",
    "np.random.seed(random_state)\n",
    "torch.manual_seed(random_state)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories and classes\n",
    "train_dir = '/content/train'\n",
    "test_dir = '/content/test'\n",
    "classes = os.listdir(train_dir)\n",
    "\n",
    "# Map labels to indices and vice versa\n",
    "label2idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "idx2label = {idx: cls for cls, idx in label2idx.items()}\n",
    "\n",
    "print(f\"Classes: {classes}\")\n",
    "print(f\"Label to Index Mapping: {label2idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize image dimensions\n",
    "img_height, img_width = 128, 128\n",
    "\n",
    "# Test loading an image\n",
    "test_img_path = '/content/train/angry/Training_10118481.jpg'\n",
    "img = cv2.imread(test_img_path)\n",
    "img = cv2.resize(img, (img_width, img_height))\n",
    "print(f\"Image height: {img_height}, Image width: {img_width}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, norm, label2idx, split='train', train_ratio=0.8):\n",
    "        self.resize = Resize((img_height, img_width))\n",
    "        self.norm = norm\n",
    "        self.split = split\n",
    "        self.train_ratio = train_ratio\n",
    "        self.img_dir = img_dir\n",
    "        self.label2idx = label2idx\n",
    "        self.img_paths, self.img_labels = self.read_img_files()\n",
    "\n",
    "        if split in ['train', 'val'] and 'train' in img_dir.lower():\n",
    "            train_data, val_data = train_test_split(\n",
    "                list(zip(self.img_paths, self.img_labels)),\n",
    "                train_size=train_ratio,\n",
    "                random_state=random_state,\n",
    "                stratify=self.img_labels\n",
    "            )\n",
    "            if split == 'train':\n",
    "                self.img_paths, self.img_labels = zip(*train_data)\n",
    "            elif split == 'val':\n",
    "                self.img_paths, self.img_labels = zip(*val_data)\n",
    "\n",
    "    def read_img_files(self):\n",
    "        img_paths, img_labels = [], []\n",
    "        for cls in self.label2idx.keys():\n",
    "            for img in os.listdir(os.path.join(self.img_dir, cls)):\n",
    "                img_paths.append(os.path.join(self.img_dir, cls, img))\n",
    "                img_labels.append(cls)\n",
    "        return img_paths, img_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        cls = self.img_labels[idx]\n",
    "        img = self.resize(read_image(img_path))\n",
    "        img = img.type(torch.float32)\n",
    "        label = self.label2idx[cls]\n",
    "        if self.norm:\n",
    "            img = (img / 127.5) - 1\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 256\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ImageDataset(train_dir, True, label2idx, split='train')\n",
    "val_dataset = ImageDataset(train_dir, True, label2idx, split='val')\n",
    "test_dataset = ImageDataset(test_dir, True, label2idx, split='test')\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a batch of images\n",
    "image_batch, label_batch = next(iter(train_loader))\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    minv = image_batch[i].numpy().min()\n",
    "    maxv = image_batch[i].numpy().max()\n",
    "    plt.imshow(np.squeeze(image_batch[i].numpy()), vmin=minv, vmax=maxv, cmap=\"gray\")\n",
    "    label = label_batch[i]\n",
    "    plt.title(idx2label[label.item()])\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dims, hidden_dims, output_dims):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dims, hidden_dims * 4)\n",
    "        self.linear2 = nn.Linear(hidden_dims * 4, hidden_dims * 2)\n",
    "        self.linear3 = nn.Linear(hidden_dims * 2, hidden_dims)\n",
    "        self.output = nn.Linear(hidden_dims, output_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.Flatten()(x)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = F.relu(x)\n",
    "        out = self.output(x)\n",
    "        return out\n",
    "\n",
    "input_dims = img_height * img_width\n",
    "hidden_dims = 64\n",
    "output_dims = len(classes)\n",
    "model = MLP(input_dims, hidden_dims, output_dims).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 40\n",
    "train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss, train_target, train_predict = 0.0, [], []\n",
    "    for X_samples, y_samples in train_loader:\n",
    "        X_samples, y_samples = X_samples.to(device), y_samples.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_samples)\n",
    "        loss = criterion(outputs, y_samples)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_target, val_predict = 0.0, [], []\n",
    "    with torch.no_grad():\n",
    "        for X_samples, y_samples in val_loader:\n",
    "            X_samples, y_samples = X_samples.to(device), y_samples.to(device)\n",
    "            outputs = model(X_samples)\n",
    "            val_loss += criterion(outputs, y_samples).item()\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_losses[-1]:.4f} | Val Loss: {val_losses[-1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test data\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for X_samples, y_samples in test_loader:\n",
    "        X_samples, y_samples = X_samples.to(device), y_samples.to(device)\n",
    "        outputs = model(X_samples)\n",
    "        test_loss += criterion(outputs, y_samples).item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
